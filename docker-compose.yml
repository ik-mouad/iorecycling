services:
  postgres:
    image: postgres:16
    container_name: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-app}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-app123}
      POSTGRES_DB: ${POSTGRES_DB:-app}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8"
    volumes:
      - pg:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-app}"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s
    restart: unless-stopped
    networks:
      - iorecycling-network

  keycloak:
    image: quay.io/keycloak/keycloak:26.0
    container_name: keycloak
    command: ["start","--http-port=8080"]
    ports:
      - "8081:8080"
    environment:
      # IMPORTANT: Les deux variables doivent être définies ensemble
      KC_BOOTSTRAP_ADMIN_USERNAME: ${KC_ADMIN_USERNAME:-${KEYCLOAK_ADMIN_USERNAME:-admin}}
      KC_BOOTSTRAP_ADMIN_PASSWORD: ${KC_ADMIN_PASSWORD:-${KEYCLOAK_ADMIN_PASSWORD:-admin}}
      KC_HTTP_ENABLED: "true"
      KC_HTTP_RELATIVE_PATH: "/auth"
      # Configuration hostname v2 (les options v1 sont obsolètes)
      KC_HOSTNAME: ${KC_HOSTNAME:-localhost}
      KC_PROXY_HEADERS: "forwarded"
      KC_PROXY_ADDRESS_FORWARDING: "true"
      KC_HOSTNAME_STRICT: "false"
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB:-app}
      KC_DB_USERNAME: ${POSTGRES_USER:-app}
      KC_DB_PASSWORD: ${POSTGRES_PASSWORD:-app123}
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "exec 3<>/dev/tcp/localhost/9000 && printf 'HEAD /auth/health/ready HTTP/1.0\\r\\nHost: localhost\\r\\n\\r\\n' >&3 && head -n 1 <&3 | grep -qE 'HTTP/1\\.0 (200|204|503)' && exec 3<&- || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 20
      start_period: 60s
    restart: unless-stopped
    networks:
      - iorecycling-network

  minio:
    image: minio/minio
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minio}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minio123}
    volumes:
      - minio:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    restart: unless-stopped
    networks:
      - iorecycling-network

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: backend
    ports:
      - "8080:8080"
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-dev}
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB:-app}
      SPRING_DATASOURCE_USERNAME: ${POSTGRES_USER:-app}
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD:-app123}
      # Configuration Flyway pour corriger les problèmes de migrations
      SPRING_FLYWAY_ENABLED: "true"
      SPRING_FLYWAY_BASELINE_ON_MIGRATE: "true"
      SPRING_FLYWAY_BASELINE_VERSION: "0"
      SPRING_FLYWAY_LOCATIONS: "classpath:db/migration"
      SPRING_FLYWAY_CLEAN_DISABLED: "true"
      # Configuration JPA
      SPRING_JPA_HIBERNATE_DDL_AUTO: "none"
      SPRING_JPA_SHOW_SQL: "false"
      # MinIO
      MINIO_ENDPOINT: http://minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ROOT_USER:-minio}
      MINIO_SECRET_KEY: ${MINIO_ROOT_PASSWORD:-minio123}
      MINIO_BUCKET: ${MINIO_BUCKET:-docs}
      # Keycloak
      KEYCLOAK_AUTH_SERVER_URL: http://keycloak:8080/auth
      KEYCLOAK_REALM: ${KEYCLOAK_REALM:-iorecycling}
      KEYCLOAK_CLIENT_ID: ${KEYCLOAK_CLIENT_ID:-iorecycling-backend}
      KEYCLOAK_ADMIN_USERNAME: ${KC_ADMIN_USERNAME:-${KEYCLOAK_ADMIN_USERNAME:-admin}}
      KEYCLOAK_ADMIN_PASSWORD: ${KC_ADMIN_PASSWORD:-${KEYCLOAK_ADMIN_PASSWORD:-admin}}
      KEYCLOAK_ADMIN_CLIENT_ID: ${KEYCLOAK_ADMIN_CLIENT_ID:-admin-cli}
      KEYCLOAK_ADMIN_REALM: ${KEYCLOAK_ADMIN_REALM:-iorecycling}
      SPRING_SECURITY_OAUTH2_RESOURCESERVER_JWT_JWK_SET_URI: http://keycloak:8080/auth/realms/${KEYCLOAK_REALM:-iorecycling}/protocol/openid-connect/certs
      # OpenTelemetry
      OTEL_EXPORTER_OTLP_ENDPOINT: http://tempo:4318
      OTEL_EXPORTER_OTLP_PROTOCOL: http/protobuf
      OTEL_LOGS_EXPORTER: none
      OTEL_METRICS_EXPORTER: none
      OTEL_TRACES_EXPORTER: otlp
      OTEL_SERVICE_NAME: iorecycling-backend
      # JVM
      JAVA_OPTS: "-Xmx512m -Xms256m -XX:+UseG1GC -XX:+UseContainerSupport -Dspring.flyway.baseline-on-migrate=true"
    volumes:
      - ./logs:/opt/iorecycling/logs/backend
    depends_on:
      postgres:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s
    restart: unless-stopped
    networks:
      - iorecycling-network

  prometheus:
    image: prom/prometheus:v2.54.1
    container_name: prometheus
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
    ports:
      - "9090:9090"
    depends_on:
      postgres:
        condition: service_healthy
      keycloak:
        condition: service_healthy
      backend:
        condition: service_healthy
      minio:
        condition: service_healthy
      frontend:
        condition: service_healthy
      caddy:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - iorecycling-network

  loki:
    image: grafana/loki:2.9.3
    container_name: loki
    ports:
      - "3100:3100"
    volumes:
      - ./monitoring/loki/loki-config.yml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    depends_on:
      postgres:
        condition: service_healthy
      keycloak:
        condition: service_healthy
      backend:
        condition: service_healthy
      minio:
        condition: service_healthy
      frontend:
        condition: service_healthy
      caddy:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - iorecycling-network

  tempo:
    image: grafana/tempo:2.3.1
    container_name: tempo
    ports:
      - "3200:3200"  # HTTP
      - "4317:4317"  # OTLP gRPC
      - "4318:4318"  # OTLP HTTP
    volumes:
      - ./monitoring/tempo/tempo-config.yml:/etc/tempo.yaml:ro
      - tempo_data:/var/tempo
    command: ["-config.file=/etc/tempo.yaml"]
    depends_on:
      postgres:
        condition: service_healthy
      keycloak:
        condition: service_healthy
      backend:
        condition: service_healthy
      minio:
        condition: service_healthy
      frontend:
        condition: service_healthy
      caddy:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - iorecycling-network

  promtail:
    image: grafana/promtail:2.9.3
    container_name: promtail
    volumes:
      - ./monitoring/promtail/promtail-config.yml:/etc/promtail/config.yml:ro
      - ./logs:/opt/iorecycling/logs/backend:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      postgres:
        condition: service_healthy
      keycloak:
        condition: service_healthy
      backend:
        condition: service_healthy
      minio:
        condition: service_healthy
      frontend:
        condition: service_healthy
      caddy:
        condition: service_healthy
      loki:
        condition: service_started
    restart: unless-stopped
    networks:
      - iorecycling-network

  grafana:
    image: grafana/grafana:11.0.0
    container_name: grafana
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      postgres:
        condition: service_healthy
      keycloak:
        condition: service_healthy
      backend:
        condition: service_healthy
      minio:
        condition: service_healthy
      frontend:
        condition: service_healthy
      caddy:
        condition: service_healthy
      prometheus:
        condition: service_started
      loki:
        condition: service_started
      tempo:
        condition: service_started
    restart: unless-stopped
    networks:
      - iorecycling-network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: frontend
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://127.0.0.1:80 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - iorecycling-network

  caddy:
    image: caddy:2
    container_name: caddy
    ports:
      - "${CADDY_PORT:-88}:88"
    volumes:
      - ./Caddyfile.local:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
    depends_on:
      frontend:
        condition: service_healthy
      backend:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://127.0.0.1:88 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - iorecycling-network

volumes:
  pg:
    driver: local
  minio:
    driver: local
  caddy_data:
    driver: local
  grafana_data:
    driver: local
  loki_data:
    driver: local
  tempo_data:
    driver: local

networks:
  iorecycling-network:
    driver: bridge
